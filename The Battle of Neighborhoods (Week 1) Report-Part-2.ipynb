{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Data "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "To solve the problem, we will need the following data: <br>\n<ul>\n<li>\nList of neighbourhoods in Kuala Lumpur. This defines the scope of this project which is \nconfined to the city of Kuala Lumpur, the capital city of the country of Malaysia in South East \nAsia.</li><br> <li>Latitude and longitude coordinates of those neighbourhoods. This is required in order to \nplot the map and also to get the venue data.</li><br> <li>Venue data, particularly data related to shopping malls. We will use this data to perform \nclustering on the neighbourhoods.</li></ul>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Sources of data and methods to extract them "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This Wikipedia page (https://en.wikipedia.org/wiki/Category:Suburbs_in_Kuala_Lumpur) contains a \nlist of neighbourhoods in Kuala Lumpur, with a total of 70 neighbourhoods. We will use web scraping \ntechniques to extract the data from the Wikipedia page, with the help of Python requests and \nbeautifulsoup packages. Then we will get the geographical coordinates of the neighbourhoods using \nPython Geocoder package which will give us the latitude and longitude coordinates of the \nneighbourhoods.  \nAfter that, we will use Foursquare API to get the venue data for those neighbourhoods. Foursquare \nhas one of the largest database of 105+ million places and is used by over 125,000 developers. \nFoursquare API will provide many categories of the venue data, we are particularly interested in the \nShopping Mall category in order to help us to solve the business problem put forward. This is a \nproject that will make use of many data science skills, from web scraping (Wikipedia), working with \nAPI (Foursquare), data cleaning, data wrangling, to machine learning (K-means clustering) and map \nvisualization (Folium). In the next section, we will present the Methodology section where we will \ndiscuss the steps taken in this project, the data analysis that we did and the machine learning \ntechnique that was used. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}